{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be39e62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcgr/Code/churn-predict/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from models.kan import KANClassifier\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "N_TRIALS = 20\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "print(f\"Running on device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73885531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: /home/pcgr/Code/churn-predict/data/customer_churn_telecom_services.csv\n",
      "Shape: (7043, 20)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Dataset\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    csv_path = 'customer_churn_telecom_services.csv'\n",
    "else:\n",
    "    csv_files = glob.glob(os.path.join(DATA_DIR, '*.csv'))\n",
    "    csv_path = csv_files[0] if csv_files else 'customer_churn_telecom_services.csv'\n",
    "\n",
    "print(f\"Loading dataset: {csv_path}\")\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"CSV not found! Place it in 'data' or project root.\")\n",
    "    raise\n",
    "\n",
    "print('Shape:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "129e55d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data...\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Cleaning & Preprocessing\n",
    "target_col = \"Churn\"\n",
    "\n",
    "def to_binary(series):\n",
    "    if series.dtype == 'O':\n",
    "        return series.str.lower().map({\n",
    "            'yes':1,'sim':1,'true':1,'y':1,'1':1,\n",
    "            'no':0,'nao':0,'false':0,'n':0,'0':0\n",
    "        }).fillna(series)\n",
    "    return series\n",
    "\n",
    "df[target_col] = to_binary(df[target_col])\n",
    "\n",
    "# Clean TotalCharges\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df = df.dropna(subset=['TotalCharges']).reset_index(drop=True)\n",
    "\n",
    "# Separate X and y\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col].astype(int)\n",
    "\n",
    "# Identify columns\n",
    "categorical_cols = [c for c in X.columns if X[c].dtype == 'O']\n",
    "numeric_cols = [c for c in X.columns if c not in categorical_cols]\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Process all data before split\n",
    "print(\"Processing data...\")\n",
    "X_processed = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed9334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: Train=(3516, 45), Val=(1758, 45), Test=(1758, 45)\n",
      "Applying SMOTE on Train...\n",
      "Before: [2581  935] | After: [2581 2581]\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Split 50/25/25 and SMOTE on Train\n",
    "\n",
    "# Split 1: 25% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_processed, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "# Split 2: 25% of original for val => 0.3333 of temp\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.3333, random_state=RANDOM_STATE, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Shapes: Train={X_train.shape}, Val={X_val.shape}, Test={X_test.shape}\")\n",
    "\n",
    "# SMOTE on Train only\n",
    "print(\"Applying SMOTE on Train...\")\n",
    "try:\n",
    "    smote = SMOTE(random_state=RANDOM_STATE)\n",
    "    X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
    "    print(f\"Before: {np.bincount(y_train)} | After: {np.bincount(y_train_bal)}\")\n",
    "except Exception as e:\n",
    "    print(f\"SMOTE failed: {e}. Using original train.\")\n",
    "    X_train_bal, y_train_bal = X_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4046131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Optuna search...\n",
      "\n",
      "Best params:\n",
      "{'n_layers': 1, 'hidden_size': 64, 'grid_size': 4, 'spline_order': 3, 'lr': 0.00019942200061167132, 'batch_size': 32, 'weight_decay': 0.00010054378956296349}\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Optuna Optimization for KAN\n",
    "def objective(trial):\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "    hidden_size = trial.suggest_categorical('hidden_size', [16, 32, 64])\n",
    "    hidden_sizes = tuple([hidden_size] * n_layers)\n",
    "\n",
    "    grid_size = trial.suggest_int('grid_size', 3, 8)\n",
    "    spline_order = trial.suggest_int('spline_order', 2, 3)\n",
    "\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64])\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "\n",
    "    model = KANClassifier(\n",
    "        hidden_sizes=hidden_sizes,\n",
    "        grid_size=grid_size,\n",
    "        spline_order=spline_order,\n",
    "        learning_rate=lr,\n",
    "        weight_decay=weight_decay,\n",
    "        batch_size=batch_size,\n",
    "        max_epochs=20,\n",
    "        device=DEVICE\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "    probs_val = model.predict_proba(X_val)[:, 1]\n",
    "    try:\n",
    "        return roc_auc_score(y_val, probs_val)\n",
    "    except ValueError:\n",
    "        return 0.5\n",
    "\n",
    "print(\"\\nStarting Optuna search...\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "print(\"\\nBest params:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e0620a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      1291\n",
      "           1       0.58      0.65      0.61       467\n",
      "\n",
      "    accuracy                           0.78      1758\n",
      "   macro avg       0.72      0.74      0.73      1758\n",
      "weighted avg       0.79      0.78      0.78      1758\n",
      "\n",
      "AUROC Final: 0.8388\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Final Training and Test Evaluation\n",
    "best_params = study.best_params\n",
    "best_hidden_sizes = tuple([best_params['hidden_size']] * best_params['n_layers'])\n",
    "\n",
    "final_model = KANClassifier(\n",
    "    hidden_sizes=best_hidden_sizes,\n",
    "    grid_size=best_params['grid_size'],\n",
    "    spline_order=best_params['spline_order'],\n",
    "    learning_rate=best_params['lr'],\n",
    "    weight_decay=best_params['weight_decay'],\n",
    "    batch_size=best_params['batch_size'],\n",
    "    max_epochs=50,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "final_model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "print(\"\\nFinal Test Results:\")\n",
    "probs_test = final_model.predict_proba(X_test)[:, 1]\n",
    "preds_test = (probs_test >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, preds_test))\n",
    "print(f\"AUROC Final: {roc_auc_score(y_test, probs_test):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
